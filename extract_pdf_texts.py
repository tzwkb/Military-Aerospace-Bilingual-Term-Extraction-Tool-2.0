#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PDFæ–‡æœ¬æå–å·¥å…·
å°†file preparationæ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶æå–ä¸ºæ–‡æœ¬ï¼Œä¿å­˜åˆ°extracted_textsæ–‡ä»¶å¤¹
æ”¯æŒPDFã€DOCXã€å›¾ç‰‡ç­‰å¤šç§æ ¼å¼çš„æ‰¹é‡å¤„ç†
"""

import sys
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
try:
    from file_processor import FileProcessor, get_file_info
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class BatchFileExtractor:
    """æ‰¹é‡æ–‡ä»¶æå–å™¨"""
    
    def __init__(self, tesseract_path: Optional[str] = None):
        """
        åˆå§‹åŒ–æ‰¹é‡æå–å™¨
        
        Args:
            tesseract_path: Tesseract OCRè·¯å¾„ï¼ˆç”¨äºå›¾ç‰‡å¤„ç†ï¼‰
        """
        self.processor = FileProcessor(tesseract_path)
        self.stats = {
            "total_files": 0,
            "success_count": 0,
            "failed_count": 0,
            "skipped_count": 0,
            "total_size": 0,
            "extracted_chars": 0
        }
    
    # =============================================================================
    # ä¸»è¦å¤„ç†æ–¹æ³•
    # =============================================================================
    
    def extract_all_files(self, 
                         source_dir: str = "file preparation",
                         output_dir: str = "extracted_texts",
                         overwrite: bool = False,
                         file_types: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        æå–æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶
        
        Args:
            source_dir: æºæ–‡ä»¶ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
            file_types: è¦å¤„ç†çš„æ–‡ä»¶ç±»å‹åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰æ”¯æŒçš„ç±»å‹
            
        Returns:
            Dict: å¤„ç†ç»“æœç»Ÿè®¡
        """
        prep_dir = Path(source_dir)
        output_path = Path(output_dir)
        
        # éªŒè¯å’Œåˆ›å»ºç›®å½•
        if not self._setup_directories(prep_dir, output_path):
            return self.stats
        
        # æ‰«ææ–‡ä»¶
        files_to_process = self._scan_files(prep_dir, file_types)
        if not files_to_process:
            return self.stats
        
        # æ˜¾ç¤ºå¤„ç†è®¡åˆ’
        self._display_processing_plan(files_to_process)
        
        # æ‰¹é‡å¤„ç†æ–‡ä»¶
        self._process_files_batch(files_to_process, output_path, overwrite)
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        self._display_final_stats()
        
        return self.stats
    
    def extract_single_file(self, 
                           file_path: str,
                           output_dir: str = "extracted_texts",
                           custom_name: Optional[str] = None) -> bool:
        """
        æå–å•ä¸ªæ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            custom_name: è‡ªå®šä¹‰è¾“å‡ºæ–‡ä»¶å
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            source_path = Path(file_path)
            output_path = Path(output_dir)
            output_path.mkdir(exist_ok=True)
            
            if not source_path.exists():
                logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
            
            # å¤„ç†æ–‡ä»¶
            return self._process_single_file(source_path, output_path, custom_name)
            
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return False
    
    # =============================================================================
    # å†…éƒ¨å¤„ç†æ–¹æ³•
    # =============================================================================
    
    def _setup_directories(self, source_dir: Path, output_dir: Path) -> bool:
        """è®¾ç½®å’ŒéªŒè¯ç›®å½•"""
        # æ£€æŸ¥æºç›®å½•
        if not source_dir.exists():
            logger.error(f"æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
            print(f"âŒ '{source_dir}' æ–‡ä»¶å¤¹ä¸å­˜åœ¨")
            return False
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        try:
            output_dir.mkdir(exist_ok=True)
            logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
        except Exception as e:
            logger.error(f"åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: {e}")
            return False
        
        return True
    
    def _scan_files(self, source_dir: Path, file_types: Optional[List[str]]) -> List[Path]:
        """æ‰«æè¦å¤„ç†çš„æ–‡ä»¶"""
        supported_formats = self.processor.get_supported_formats()
        
        if file_types:
            # è¿‡æ»¤ç”¨æˆ·æŒ‡å®šçš„ç±»å‹
            target_types = [t.lower().lstrip('.') for t in file_types]
            supported_formats = [f for f in supported_formats if f in target_types]
        
        files_to_process = []
        
        for fmt in supported_formats:
            pattern = f"*.{fmt}"
            found_files = list(source_dir.glob(pattern))
            files_to_process.extend(found_files)
        
        # æŒ‰æ–‡ä»¶åæ’åº
        files_to_process.sort(key=lambda x: x.name.lower())
        
        self.stats["total_files"] = len(files_to_process)
        
        if not files_to_process:
            print(f"âŒ åœ¨ '{source_dir}' ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„æ–‡ä»¶")
            print(f"æ”¯æŒçš„æ ¼å¼: {', '.join(supported_formats)}")
        
        return files_to_process
    
    def _display_processing_plan(self, files: List[Path]):
        """æ˜¾ç¤ºå¤„ç†è®¡åˆ’"""
        print(f"\nğŸ“š æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶å¾…å¤„ç†")
        print("=" * 70)
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        type_stats = {}
        total_size = 0
        
        for file_path in files:
            try:
                file_info = get_file_info(str(file_path))
                file_type = file_info['type']
                file_size = file_info['size']
                
                if file_type not in type_stats:
                    type_stats[file_type] = {"count": 0, "size": 0}
                
                type_stats[file_type]["count"] += 1
                type_stats[file_type]["size"] += file_size
                total_size += file_size
                
            except Exception as e:
                logger.warning(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {file_path.name}: {e}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print("æ–‡ä»¶ç±»å‹ç»Ÿè®¡:")
        for file_type, stats in type_stats.items():
            size_mb = stats["size"] / (1024 * 1024)
            print(f"  {file_type.upper()}: {stats['count']} ä¸ªæ–‡ä»¶, {size_mb:.1f} MB")
        
        self.stats["total_size"] = total_size
        print(f"\næ€»å¤§å°: {total_size / (1024 * 1024):.1f} MB")
        print("-" * 70)
    
    def _process_files_batch(self, files: List[Path], output_dir: Path, overwrite: bool):
        """æ‰¹é‡å¤„ç†æ–‡ä»¶"""
        for i, file_path in enumerate(files, 1):
            print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(files)}: {file_path.name}")
            
            try:
                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                output_file = output_dir / f"{file_path.stem}.txt"
                if output_file.exists() and not overwrite:
                    print(f"   â­ï¸  è·³è¿‡ï¼ˆæ–‡ä»¶å·²å­˜åœ¨ï¼‰: {output_file.name}")
                    self.stats["skipped_count"] += 1
                    continue
                
                # å¤„ç†æ–‡ä»¶
                success = self._process_single_file(file_path, output_dir)
                
                if success:
                    self.stats["success_count"] += 1
                else:
                    self.stats["failed_count"] += 1
                    
            except KeyboardInterrupt:
                print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
                break
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶å¼‚å¸¸ {file_path.name}: {e}")
                self.stats["failed_count"] += 1
    
    def _process_single_file(self, 
                           file_path: Path, 
                           output_dir: Path,
                           custom_name: Optional[str] = None) -> bool:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_size = file_path.stat().st_size
            print(f"   æ–‡ä»¶å¤§å°: {file_size / 1024:.1f} KB")
            
            # æå–æ–‡æœ¬
            file_type, text_list = self.processor.process_file(str(file_path))
            
            if not text_list or not any(text.strip() for text in text_list):
                print(f"   âš ï¸  æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•æå–æ–‡æœ¬")
                return False
            
            # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
            full_text = self._combine_texts(text_list, file_path.name)
            
            # ä¿å­˜æ–‡ä»¶
            output_name = custom_name or f"{file_path.stem}.txt"
            output_file = output_dir / output_name
            
            success = self._save_extracted_text(full_text, output_file, file_path)
            
            if success:
                char_count = len(full_text)
                self.stats["extracted_chars"] += char_count
                print(f"   âœ… æˆåŠŸæå– {char_count:,} å­—ç¬¦")
                print(f"   ğŸ’¾ ä¿å­˜è‡³: {output_file.name}")
            
            return success
            
        except Exception as e:
            print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return False
    
    def _combine_texts(self, text_list: List[str], filename: str) -> str:
        """åˆå¹¶æ–‡æœ¬åˆ—è¡¨"""
        if len(text_list) == 1:
            return text_list[0]
        
        # å¤šä¸ªæ–‡æœ¬å—çš„æƒ…å†µï¼Œæ·»åŠ åˆ†é¡µæ ‡è®°
        combined_parts = []
        for i, text in enumerate(text_list, 1):
            if text.strip():
                # å¦‚æœæ–‡æœ¬å·²ç»æœ‰æ ‡è®°ï¼Œå°±ä¸é‡å¤æ·»åŠ 
                if not text.startswith('[é¡µé¢') and not text.startswith('[æ–‡ä»¶'):
                    combined_parts.append(f"[é¡µé¢ {i}]\n{text.strip()}")
                else:
                    combined_parts.append(text.strip())
        
        return '\n\n'.join(combined_parts)
    
    def _save_extracted_text(self, text: str, output_file: Path, source_file: Path) -> bool:
        """ä¿å­˜æå–çš„æ–‡æœ¬"""
        try:
            # ç›´æ¥å†™å…¥æå–çš„æ–‡æœ¬ï¼Œä¸æ·»åŠ å¤´éƒ¨ä¿¡æ¯
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(text)
            
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {output_file}: {e}")
            return False
    
    
    def _display_final_stats(self):
        """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n" + "=" * 70)
        print("ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡")
        print("=" * 70)
        print(f"æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        print(f"æˆåŠŸå¤„ç†: {self.stats['success_count']} âœ…")
        print(f"å¤„ç†å¤±è´¥: {self.stats['failed_count']} âŒ")
        print(f"è·³è¿‡æ–‡ä»¶: {self.stats['skipped_count']} â­ï¸")
        
        if self.stats['success_count'] > 0:
            success_rate = (self.stats['success_count'] / self.stats['total_files']) * 100
            print(f"æˆåŠŸç‡: {success_rate:.1f}%")
            
            total_mb = self.stats['total_size'] / (1024 * 1024)
            chars_k = self.stats['extracted_chars'] / 1000
            print(f"å¤„ç†æ•°æ®: {total_mb:.1f} MB â†’ {chars_k:.1f}K å­—ç¬¦")
        
        print("=" * 70)
    
    # =============================================================================
    # å·¥å…·æ–¹æ³•
    # =============================================================================
    
    def get_processor_info(self) -> Dict[str, Any]:
        """è·å–å¤„ç†å™¨ä¿¡æ¯"""
        return self.processor.get_processor_info()


# =============================================================================
# å‘½ä»¤è¡Œæ¥å£
# =============================================================================

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="æ‰¹é‡æ–‡ä»¶æ–‡æœ¬æå–å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python extract_pdf_texts.py                    # å¤„ç†æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶
  python extract_pdf_texts.py --types pdf docx   # åªå¤„ç†PDFå’ŒDOCXæ–‡ä»¶
  python extract_pdf_texts.py --file sample.pdf  # å¤„ç†å•ä¸ªæ–‡ä»¶
  python extract_pdf_texts.py --overwrite        # è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
        """
    )
    
    parser.add_argument("--source", "-s", default="file preparation",
                       help="æºæ–‡ä»¶ç›®å½• (é»˜è®¤: file preparation)")
    parser.add_argument("--output", "-o", default="extracted_texts",
                       help="è¾“å‡ºç›®å½• (é»˜è®¤: extracted_texts)")
    parser.add_argument("--types", "-t", nargs="+", 
                       help="è¦å¤„ç†çš„æ–‡ä»¶ç±»å‹ (å¦‚: pdf docx txt)")
    parser.add_argument("--file", "-f", help="å¤„ç†å•ä¸ªæ–‡ä»¶")
    parser.add_argument("--overwrite", action="store_true",
                       help="è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶")
    parser.add_argument("--tesseract-path", help="Tesseract OCRå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--info", action="store_true", help="æ˜¾ç¤ºå¤„ç†å™¨ä¿¡æ¯")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæå–å™¨
    extractor = BatchFileExtractor(args.tesseract_path)
    
    # æ˜¾ç¤ºå¤„ç†å™¨ä¿¡æ¯
    if args.info:
        info = extractor.get_processor_info()
        print("ğŸ“‹ æ–‡ä»¶å¤„ç†å™¨ä¿¡æ¯:")
        print(f"æ”¯æŒæ ¼å¼: {', '.join(info['supported_formats'])}")
        print(f"å¯ç”¨æå–å™¨: {', '.join(info['available_extractors'])}")
        print(f"OCRåŠŸèƒ½: {'å¯ç”¨' if info['ocr_enabled'] else 'ç¦ç”¨'}")
        return
    
    print("ğŸ‰ æ‰¹é‡æ–‡ä»¶æ–‡æœ¬æå–å·¥å…·")
    print("=" * 50)
    
    try:
        if args.file:
            # å¤„ç†å•ä¸ªæ–‡ä»¶
            success = extractor.extract_single_file(
                args.file, 
                args.output,
                None
            )
            if success:
                print("âœ… æ–‡ä»¶å¤„ç†å®Œæˆ")
            else:
                print("âŒ æ–‡ä»¶å¤„ç†å¤±è´¥")
        else:
            # æ‰¹é‡å¤„ç†
            stats = extractor.extract_all_files(
                source_dir=args.source,
                output_dir=args.output,
                overwrite=args.overwrite,
                file_types=args.types
            )
            
            if stats['success_count'] > 0:
                print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼æˆåŠŸæå– {stats['success_count']} ä¸ªæ–‡ä»¶")
            else:
                print("\nâŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶")
                
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
