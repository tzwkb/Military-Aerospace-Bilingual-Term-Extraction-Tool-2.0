#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAI GPTæ‰¹å¤„ç†æœ¯è¯­æŠ½å– - ä¸»ç¨‹åº
æä¾›ç®€å•çš„å‘½ä»¤è¡Œç•Œé¢å’Œå¿«é€Ÿé…ç½®é€‰é¡¹
"""

import os
import sys
import argparse
from pathlib import Path
from typing import List, Optional, Tuple

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
try:
    from gpt_processor import GPTProcessor, load_texts_from_file
    from config import (
        OPENAI_API_KEY, OPENAI_BASE_URL, BATCH_CONFIG,
        SYSTEM_PROMPT, get_user_prompt, TEXT_SPLITTING
    )
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰å¿…è¦çš„æ–‡ä»¶éƒ½åœ¨å½“å‰ç›®å½•ä¸­")
    sys.exit(1)


class TermExtractionApp:
    """æœ¯è¯­æŠ½å–åº”ç”¨ç±»"""
    
    def __init__(self):
        self.api_key = None
        self.processor = None
        
    # =============================================================================
    # APIå¯†é’¥ç®¡ç†
    # =============================================================================
    
    def setup_api_key(self) -> bool:
        """è®¾ç½®APIå¯†é’¥"""
        # ä¼˜å…ˆçº§: å‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é…ç½®æ–‡ä»¶ > ç”¨æˆ·è¾“å…¥
        if self.api_key:
            return True
            
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        env_key = os.getenv("OPENAI_API_KEY")
        if env_key and env_key != "your-openai-api-key-here":
            self.api_key = env_key
            return True
            
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        if OPENAI_API_KEY != "your-openai-api-key-here":
            self.api_key = OPENAI_API_KEY
            return True
            
        # ç”¨æˆ·è¾“å…¥
        return self._prompt_for_api_key()
    
    def _prompt_for_api_key(self) -> bool:
        """æç¤ºç”¨æˆ·è¾“å…¥APIå¯†é’¥"""
        print("ğŸ”‘ è¯·è¾“å…¥æ‚¨çš„OpenAI APIå¯†é’¥:")
        print("   æ‚¨å¯ä»¥åœ¨ https://platform.openai.com/api-keys è·å–APIå¯†é’¥")
        api_key = input("APIå¯†é’¥: ").strip()
        
        if api_key:
            self.api_key = api_key
            
            # è¯¢é—®æ˜¯å¦ä¿å­˜åˆ°ç¯å¢ƒå˜é‡
            save_env = input("æ˜¯å¦ä¿å­˜åˆ°ç¯å¢ƒå˜é‡? (y/N): ").strip().lower()
            if save_env in ['y', 'yes', 'æ˜¯']:
                print(f"è¯·åœ¨æ‚¨çš„shellé…ç½®æ–‡ä»¶ä¸­æ·»åŠ :")
                print(f"export OPENAI_API_KEY='{api_key}'")
            
            return True
        
        print("âŒ æœªæä¾›APIå¯†é’¥")
        return False
    
    # =============================================================================
    # è¾“å…¥å¤„ç†
    # =============================================================================
    
    def get_input_texts(self) -> List[str]:
        """è·å–è¾“å…¥æ–‡æœ¬"""
        print("\nğŸ“ è¯·é€‰æ‹©è¾“å…¥æ–¹å¼:")
        print("1. ä»æ–‡ä»¶è¯»å–")
        print("2. ç›´æ¥è¾“å…¥æ–‡æœ¬")
        print("3. ä½¿ç”¨ç¤ºä¾‹æ–‡æœ¬")
        
        while True:
            choice = input("é€‰æ‹©æ–¹å¼ (1-3): ").strip()
            
            if choice == "1":
                return self._load_from_file()
            elif choice == "2":
                return self._input_texts_directly()
            elif choice == "3":
                return self._use_sample_texts()
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
    
    def _input_texts_directly(self) -> List[str]:
        """ç›´æ¥è¾“å…¥æ–‡æœ¬"""
        texts = []
        print("\nâœï¸ è¯·è¾“å…¥æ–‡æœ¬ (æ¯è¡Œä¸€ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸ):")
        
        while True:
            text = input().strip()
            if not text:
                break
            texts.append(text)
        
        if not texts:
            print("âŒ æœªè¾“å…¥ä»»ä½•æ–‡æœ¬")
        else:
            print(f"âœ… è¾“å…¥äº† {len(texts)} ä¸ªæ–‡æœ¬")
        
        return texts
    
    def _use_sample_texts(self) -> List[str]:
        """ä½¿ç”¨ç¤ºä¾‹æ–‡æœ¬"""
        sample_texts = [
            "BWB-UCAVæ¨¡å‹é‡‡ç”¨ç¿¼èº«èåˆä½“æ„å‹ï¼Œåœ¨ä½é€Ÿé£æ´è¯•éªŒä¸­æµ‹å¾—å‡é˜»æ¯”ä¸º12.5ï¼Œå¤±é€Ÿæ”»è§’ä¸º18Â°ã€‚",
            "é€šè¿‡PIVç²’å­å›¾åƒæµ‹é€ŸæŠ€æœ¯å’ŒCFDè®¡ç®—æµä½“åŠ›å­¦ä»¿çœŸï¼Œåˆ†æäº†ä¸åŒæ”»è§’ä¸‹çš„æµåœºç‰¹å¾å’Œå‹åŠ›åˆ†å¸ƒã€‚",
            "å¤åˆææ–™èœ‚çªå¤¹èŠ¯ç»“æ„å…·æœ‰é«˜æ¯”å¼ºåº¦å’Œæ¯”åˆšåº¦ï¼ŒCFRPç¢³çº¤ç»´å¢å¼ºå¡‘æ–™å¹¿æ³›åº”ç”¨äºèˆªç©ºå™¨ä¸»æ‰¿åŠ›ç»“æ„ã€‚",
            "é£è¡Œå™¨é‡‡ç”¨å…ˆè¿›çš„é£æ§ç³»ç»ŸFCSï¼Œé›†æˆäº†GPSå…¨çƒå®šä½ç³»ç»Ÿå’ŒINSæƒ¯æ€§å¯¼èˆªç³»ç»Ÿï¼Œå®ç°è‡ªä¸»é£è¡Œã€‚",
            "é£æ´è¯•éªŒé‡‡ç”¨å…­åˆ†é‡å¤©å¹³æµ‹é‡æ°”åŠ¨åŠ›å’ŒåŠ›çŸ©ï¼Œé›·è¯ºæ•°Reä¸º2.4Ã—10^6ï¼Œé©¬èµ«æ•°Maä¸º0.3ã€‚"
        ]
        
        print(f"âœ… ä½¿ç”¨ {len(sample_texts)} ä¸ªç¤ºä¾‹æ–‡æœ¬")
        return sample_texts
    
    # =============================================================================
    # æ–‡ä»¶å¤„ç†
    # =============================================================================
    
    def _load_from_file(self) -> List[str]:
        """ä»æ–‡ä»¶åŠ è½½æ–‡æœ¬ - é»˜è®¤å¤„ç†file preparationæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
        prep_files = self._scan_preparation_folder()
        
        if prep_files:
            return self._handle_preparation_files(prep_files)
        else:
            print(f"\nğŸ“ 'file preparation' æ–‡ä»¶å¤¹ä¸ºç©ºæˆ–ä¸å­˜åœ¨")
            print("ğŸ’¡ å»ºè®®å°†è¦å¤„ç†çš„æ–‡ä»¶æ”¾å…¥ 'file preparation' æ–‡ä»¶å¤¹ä¸­")
            return self._select_from_other_locations()
    
    def _scan_preparation_folder(self) -> List[Path]:
        """æ‰«æfile preparationæ–‡ä»¶å¤¹"""
        prep_dir = Path("file preparation")
        supported_extensions = ["*.txt", "*.pdf", "*.docx", "*.doc", "*.md", "*.csv"]
        
        prep_files = []
        if prep_dir.exists():
            for ext in supported_extensions:
                prep_files.extend(prep_dir.glob(ext))
        
        return prep_files
    
    def _handle_preparation_files(self, prep_files: List[Path]) -> List[str]:
        """å¤„ç†preparationæ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶"""
        self._display_file_list(prep_files, "file preparation")
        
        print("\nğŸ”„ å¤„ç†é€‰é¡¹:")
        print("1. å¤„ç†æ‰€æœ‰æ–‡ä»¶ (æ¨è)")
        print("2. é€‰æ‹©å•ä¸ªæ–‡ä»¶")
        print("3. é€‰æ‹©å…¶ä»–ä½ç½®çš„æ–‡ä»¶")
        
        while True:
            choice = input("é€‰æ‹©å¤„ç†æ–¹å¼ (1-3): ").strip()
            
            if choice == "1":
                return self._process_multiple_files(prep_files)
            elif choice == "2":
                return self._select_single_file(prep_files)
            elif choice == "3":
                return self._select_from_other_locations()
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
    
    def _display_file_list(self, files: List[Path], location: str):
        """æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨"""
        print(f"\nğŸ“ åœ¨ '{location}' ä¸­æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶:")
        total_size = 0
        
        for i, file in enumerate(files, 1):
            file_size = file.stat().st_size
            total_size += file_size
            size_str = self._format_file_size(file_size)
            file_type = file.suffix.upper()
            print(f"  {i}. {file.name} {size_str} [{file_type}]")
        
        total_size_str = self._format_file_size(total_size)
        print(f"\nğŸ“Š æ€»è®¡: {len(files)} ä¸ªæ–‡ä»¶ï¼Œ{total_size_str}")
    
    def _format_file_size(self, size: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size < 1024:
            return f"({size} bytes)"
        elif size < 1024 * 1024:
            return f"({size/1024:.1f} KB)"
        else:
            return f"({size/(1024*1024):.1f} MB)"
    
    def _process_multiple_files(self, files: List[Path]) -> List[str]:
        """å¤„ç†å¤šä¸ªæ–‡ä»¶"""
        all_texts = []
        
        # è·å–åˆ†å‰²é…ç½®
        chunk_size, use_smart_splitter, overlap_size = self._get_splitting_config()
        
        print(f"\nğŸ”„ å¼€å§‹å¤„ç† {len(files)} ä¸ªæ–‡ä»¶...")
        
        for i, file_path in enumerate(files, 1):
            try:
                print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶ {i}/{len(files)}: {file_path.name}")
                texts = self._process_single_file_content(
                    file_path, chunk_size, use_smart_splitter, overlap_size
                )
                all_texts.extend(texts)
                print(f"  âœ… æˆåŠŸæå– {len(texts)} ä¸ªæ–‡æœ¬å—")
                
            except Exception as e:
                print(f"  âŒ å¤„ç†æ–‡ä»¶ {file_path.name} å¤±è´¥: {e}")
                continue
        
        print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆï¼æ€»å…±è·å¾— {len(all_texts)} ä¸ªæ–‡æœ¬å—")
        return all_texts
    
    def _select_single_file(self, files: List[Path]) -> List[str]:
        """é€‰æ‹©å•ä¸ªæ–‡ä»¶å¤„ç†"""
        print("\nğŸ“‹ è¯·é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶:")
        for i, file in enumerate(files, 1):
            file_size = file.stat().st_size
            size_str = self._format_file_size(file_size)
            print(f"{i}. {file.name} {size_str}")
        
        while True:
            try:
                choice = input("é€‰æ‹©æ–‡ä»¶ (è¾“å…¥ç¼–å·): ").strip()
                idx = int(choice) - 1
                if 0 <= idx < len(files):
                    file_path = files[idx]
                    break
                else:
                    print("âŒ æ— æ•ˆç¼–å·")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æ•°å­—")
        
        return self._process_single_file(file_path)
    
    def _select_from_other_locations(self) -> List[str]:
        """ä»å…¶ä»–ä½ç½®é€‰æ‹©æ–‡ä»¶"""
        supported_files = self._scan_other_locations()
        
        if supported_files:
            self._display_file_list(supported_files, "å…¶ä»–ä½ç½®")
            
            while True:
                try:
                    choice = input("é€‰æ‹©æ–‡ä»¶ (è¾“å…¥ç¼–å·): ").strip()
                    idx = int(choice) - 1
                    if 0 <= idx < len(supported_files):
                        file_path = supported_files[idx]
                        break
                    else:
                        print("âŒ æ— æ•ˆç¼–å·")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æ•°å­—")
        else:
            file_path = Path(input("è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„: ").strip())
        
        return self._process_single_file(file_path)
    
    def _scan_other_locations(self) -> List[Path]:
        """æ‰«æå…¶ä»–ä½ç½®çš„æ–‡ä»¶"""
        supported_files = []
        supported_extensions = ["*.txt", "*.pdf", "*.docx", "*.doc", "*.md", "*.csv"]
        
        # æ£€æŸ¥extracted_textsç›®å½•
        extracted_dir = Path("extracted_texts")
        if extracted_dir.exists():
            for ext in supported_extensions:
                supported_files.extend(extracted_dir.glob(ext))
        
        # æ£€æŸ¥å½“å‰ç›®å½•çš„æ”¯æŒæ–‡ä»¶
        for ext in supported_extensions:
            current_files = list(Path(".").glob(ext))
            # æ’é™¤file preparationæ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
            for file in current_files:
                if not str(file).startswith("file preparation"):
                    supported_files.append(file)
        
        return supported_files
    
    # =============================================================================
    # æ–‡æœ¬åˆ†å‰²é…ç½®
    # =============================================================================
    
    def _get_splitting_config(self) -> Tuple[Optional[int], bool, int]:
        """è·å–æ–‡æœ¬åˆ†å‰²é…ç½®"""
        print("\nğŸ“ æ–‡æœ¬åˆ†å‰²é…ç½®:")
        print("1. æ™ºèƒ½åˆ†å‰² (æ¨è) - æŒ‰æ®µè½å’Œè¯­ä¹‰è¾¹ç•Œåˆ†å‰²")
        print("2. æ•´æ–‡æ¡£å¤„ç† - åˆ©ç”¨128Kä¸Šä¸‹æ–‡å¤„ç†å®Œæ•´æ–‡æ¡£")
        print("3. æŒ‰æ®µè½å¤„ç† - é€‚åˆçŸ­æ–‡æœ¬æˆ–å•è¡Œæœ¯è¯­")
        
        while True:
            choice = input("é€‰æ‹©åˆ†å‰²æ–¹å¼ (1-3, é»˜è®¤1): ").strip() or "1"
            if choice in ["1", "2", "3"]:
                break
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
        
        if choice == "1":
            return self._get_smart_splitting_config()
        elif choice == "2":
            return self._get_whole_document_config()
        else:
            return None, False, 0  # æŒ‰æ®µè½å¤„ç†
    
    def _get_smart_splitting_config(self) -> Tuple[int, bool, int]:
        """è·å–æ™ºèƒ½åˆ†å‰²é…ç½®"""
        default_chunk = TEXT_SPLITTING["default_chunk_size"]
        default_overlap = TEXT_SPLITTING["default_overlap_size"]
        min_chunk = TEXT_SPLITTING["min_chunk_size"]
        max_chunk = TEXT_SPLITTING["max_chunk_size"]
        
        # è·å–å—å¤§å°
        while True:
            try:
                chunk_size = int(input(
                    f"è¯·è¾“å…¥å—å¤§å° (å­—ç¬¦æ•°, {min_chunk}-{max_chunk}, é»˜è®¤{default_chunk}): "
                ) or str(default_chunk))
                
                if chunk_size < min_chunk:
                    print(f"âš ï¸  å—å¤§å°è¿‡å°ï¼Œå»ºè®®è‡³å°‘{min_chunk}å­—ç¬¦")
                    continue
                if chunk_size > max_chunk:
                    print(f"âš ï¸  å—å¤§å°è¿‡å¤§ï¼Œå»ºè®®ä¸è¶…è¿‡{max_chunk}å­—ç¬¦")
                    continue
                break
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
        
        # è·å–é‡å å¤§å°
        while True:
            try:
                overlap_size = int(input(
                    f"è¯·è¾“å…¥é‡å å¤§å° (å­—ç¬¦æ•°, é»˜è®¤{default_overlap}): "
                ) or str(default_overlap))
                
                max_overlap = int(chunk_size * TEXT_SPLITTING["max_overlap_ratio"])
                if overlap_size >= chunk_size:
                    print("âš ï¸  é‡å å¤§å°ä¸èƒ½å¤§äºç­‰äºå—å¤§å°")
                    continue
                if overlap_size > max_overlap:
                    ratio_percent = int(TEXT_SPLITTING['max_overlap_ratio'] * 100)
                    print(f"âš ï¸  é‡å å¤§å°è¿‡å¤§ï¼Œä¸åº”è¶…è¿‡å—å¤§å°çš„{ratio_percent}% ({max_overlap}å­—ç¬¦)")
                    continue
                break
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
        
        return chunk_size, True, overlap_size
    
    def _get_whole_document_config(self) -> Tuple[int, bool, int]:
        """è·å–æ•´æ–‡æ¡£å¤„ç†é…ç½®"""
        threshold = TEXT_SPLITTING.get("whole_document_threshold", 300000)
        print(f"\nğŸ”„ æ•´æ–‡æ¡£æ¨¡å¼:")
        print(f"   â€¢ é€‚ç”¨äº â‰¤ {threshold:,} å­—ç¬¦çš„æ–‡æ¡£ (çº¦{threshold//4000:.0f}K tokens)")
        print(f"   â€¢ åˆ©ç”¨æ¨¡å‹çš„128Kæ€»ä¸Šä¸‹æ–‡")
        print(f"   â€¢ é¢„ç•™28K tokensç»™æç¤ºè¯å’Œè¾“å‡º")
        print(f"   â€¢ ä¸€æ¬¡æ€§å¤„ç†å®Œæ•´æ–‡æ¡£ï¼Œå‡å°‘ä¿¡æ¯ä¸¢å¤±")
        return threshold, True, 0  # æ•´æ–‡æ¡£æ¨¡å¼ï¼Œæ— é‡å 
    
    # =============================================================================
    # æ–‡ä»¶å¤„ç†æ ¸å¿ƒé€»è¾‘
    # =============================================================================
    
    def _process_single_file(self, file_path: Path) -> List[str]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        chunk_size, use_smart_splitter, overlap_size = self._get_splitting_config()
        return self._process_single_file_content(
            file_path, chunk_size, use_smart_splitter, overlap_size
        )
    
    def _process_single_file_content(
        self, 
        file_path: Path, 
        chunk_size: Optional[int], 
        use_smart_splitter: bool, 
        overlap_size: int
    ) -> List[str]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶å†…å®¹"""
        try:
            texts = load_texts_from_file(
                str(file_path), 
                chunk_size=chunk_size,
                use_smart_splitter=use_smart_splitter,
                overlap_size=overlap_size
            )
            
            # æ™ºèƒ½åˆ†å‰²å™¨å·²ç»åœ¨å†…éƒ¨æ·»åŠ äº†æ–‡ä»¶æ ‡è¯†ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤æ·»åŠ 
            if use_smart_splitter and chunk_size:
                return texts
            else:
                # ä¸ºç®€å•åˆ†å‰²æ·»åŠ æ¥æºæ ‡è¯†
                return self._add_file_labels(texts, file_path.name)
                
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def _add_file_labels(self, texts: List[str], filename: str) -> List[str]:
        """ä¸ºæ–‡æœ¬æ·»åŠ æ–‡ä»¶æ ‡ç­¾"""
        file_texts = []
        for j, text in enumerate(texts, 1):
            if len(texts) > 1:
                labeled_text = f"[æ–‡ä»¶: {filename} - ç¬¬{j}éƒ¨åˆ†]\n{text}"
            else:
                labeled_text = f"[æ–‡ä»¶: {filename}]\n{text}"
            file_texts.append(labeled_text)
        return file_texts
    
    # =============================================================================
    # è¾“å‡ºé…ç½®
    # =============================================================================
    
    def select_output_format(self) -> str:
        """é€‰æ‹©è¾“å‡ºæ ¼å¼"""
        formats = {
            "1": "json",
            "2": "csv", 
            "3": "excel",
            "4": "tbx",
            "5": "txt"
        }
        
        print("\nğŸ“Š è¯·é€‰æ‹©è¾“å‡ºæ ¼å¼:")
        print("1. JSON (ç»“æ„åŒ–æ•°æ®)")
        print("2. CSV (è¡¨æ ¼æ•°æ®)")
        print("3. Excel (å¸¦æ ·å¼å’Œç»Ÿè®¡ä¿¡æ¯)")
        print("4. TBX (æœ¯è¯­ç®¡ç†æ ‡å‡†XMLæ ¼å¼)")
        print("5. TXT (çº¯æ–‡æœ¬)")
        
        while True:
            choice = input("é€‰æ‹©æ ¼å¼ (1-5): ").strip()
            if choice in formats:
                return formats[choice]
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
    
    def select_model(self) -> str:
        """é€‰æ‹©æ¨¡å‹"""
        from config import DEFAULT_MODEL
        print(f"\nğŸ¤– ä½¿ç”¨æ¨¡å‹: {DEFAULT_MODEL}")
        return DEFAULT_MODEL
    
    def select_extraction_mode(self) -> bool:
        """é€‰æ‹©æœ¯è¯­æå–æ¨¡å¼ï¼ˆå•è¯­/åŒè¯­ï¼‰"""
        print("\nğŸŒ è¯·é€‰æ‹©æœ¯è¯­æå–æ¨¡å¼:")
        print("1. åŒè¯­æ¨¡å¼ (æ¨è) - åŒæ—¶æå–è‹±æ–‡å’Œä¸­æ–‡æœ¯è¯­")
        print("2. å•è¯­æ¨¡å¼ - ä»…æå–åŸæ–‡æœ¯è¯­ï¼ˆä¸­æ–‡æ–‡æ¡£æå–ä¸­æ–‡ï¼Œè‹±æ–‡æ–‡æ¡£æå–è‹±æ–‡ï¼‰")
        print("\nğŸ’¡ æç¤º:")
        print("  - åŒè¯­æ¨¡å¼: é€‚åˆå»ºç«‹åŒè¯­æœ¯è¯­åº“ã€è¾…åŠ©ç¿»è¯‘ã€å­¦ä¹ ææ–™")
        print("  - å•è¯­æ¨¡å¼: é€‚åˆå¿«é€Ÿæå–ã€é™ä½æˆæœ¬ã€ä¿æŒåŸæ–‡æ ¼å¼")
        
        while True:
            choice = input("\nè¯·é€‰æ‹© (1-2ï¼Œé»˜è®¤1): ").strip() or "1"
            if choice == "1":
                print("âœ… å·²é€‰æ‹©: åŒè¯­æ¨¡å¼")
                return True  # bilingual=True
            elif choice == "2":
                print("âœ… å·²é€‰æ‹©: å•è¯­æ¨¡å¼")
                return False  # bilingual=False
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1æˆ–2")
    
    def handle_output_generation(self, results: dict, source_files: List[str], model: str) -> List[str]:
        """
        å¤„ç†è¾“å‡ºæ–‡ä»¶ç”Ÿæˆï¼Œæ”¯æŒé‡å¤é€‰æ‹©ä¸åŒæ ¼å¼
        
        Args:
            results: å¤„ç†ç»“æœ
            source_files: æºæ–‡ä»¶åˆ—è¡¨
            model: ä½¿ç”¨çš„æ¨¡å‹
            
        Returns:
            List[str]: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if not results or not results.get('merged_results'):
            print("âŒ æ²¡æœ‰å¯ç”¨çš„å¤„ç†ç»“æœ")
            return []
        
        merged_results = results['merged_results']
        generated_files = []
        
        # æå–å…ƒæ•°æ®ç”¨äºæ–‡ä»¶å‘½å
        source_filename = self.processor._extract_source_filename(source_files)
        model_name = model.replace("-", "").replace(".", "")  # æ¸…ç†æ¨¡å‹åç”¨äºæ–‡ä»¶å
        total_terms = self.processor._count_total_terms(merged_results)
        
        print(f"\nğŸ‰ æœ¯è¯­æŠ½å–å®Œæˆï¼")
        print(f"ğŸ“Š å…±æå– {total_terms} ä¸ªæœ¯è¯­")
        print(f"ğŸ“ æ¥æºæ–‡ä»¶: {source_filename}")
        
        while True:
            print("\n" + "="*50)
            output_format = self.select_output_format()
            
            try:
                # ç”ŸæˆæŒ‡å®šæ ¼å¼çš„æ–‡ä»¶
                output_file = self.processor.save_processed_results(
                    merged_results, 
                    output_format,
                    source_filename,
                    model_name,
                    total_terms
                )
                
                generated_files.append(output_file)
                print(f"âœ… {output_format.upper()}æ–‡ä»¶å·²ç”Ÿæˆ: {output_file}")
                
            except Exception as e:
                print(f"âŒ ç”Ÿæˆ{output_format.upper()}æ–‡ä»¶å¤±è´¥: {e}")
                continue
            
            # è¯¢é—®æ˜¯å¦ç»§ç»­ç”Ÿæˆå…¶ä»–æ ¼å¼
            print(f"\nğŸ“‹ å·²ç”Ÿæˆçš„æ–‡ä»¶:")
            for i, file_path in enumerate(generated_files, 1):
                file_format = file_path.split('.')[-1].upper()
                print(f"  {i}. {file_format}æ ¼å¼: {file_path}")
            
            while True:
                continue_choice = input("\næ˜¯å¦ç”Ÿæˆå…¶ä»–æ ¼å¼çš„æ–‡ä»¶? (y/N): ").strip().lower()
                if continue_choice in ['y', 'yes', 'æ˜¯']:
                    break
                elif continue_choice in ['n', 'no', 'å¦', '']:
                    return generated_files
                else:
                    print("âŒ è¯·è¾“å…¥ y/yes/æ˜¯ æˆ– n/no/å¦")
        
        return generated_files
    
    # =============================================================================
    # æ‰¹å¤„ç†æ‰§è¡Œ
    # =============================================================================
    
    def _extract_source_files(self, texts: List[str]) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–æ¥æºæ–‡ä»¶å"""
        import re
        source_files = []
        
        for text in texts:
            # æŸ¥æ‰¾æ–‡æœ¬å¼€å¤´çš„æ–‡ä»¶æ ‡è¯†
            match = re.search(r'\[æ–‡ä»¶: ([^\]]+)\]', text)
            if match:
                filename = match.group(1)
                # ç§»é™¤éƒ¨åˆ†æ ‡è¯†ï¼Œåªä¿ç•™æ–‡ä»¶å
                filename = re.sub(r' - ç¬¬\d+éƒ¨åˆ†$', '', filename)
                source_files.append(filename)
            else:
                source_files.append("")
        
        return source_files
    
    def run_batch_processing(
        self, 
        texts: List[str], 
        model: str,
        bilingual: bool = True
    ) -> Optional[dict]:
        """è¿è¡Œæ‰¹å¤„ç†ï¼ˆä¸åŒ…å«è¾“å‡ºæ ¼å¼ï¼Œåªè¿›è¡ŒæŠ½å–ï¼‰"""
        if not self.processor:
            # è·å–base_urlé…ç½®
            base_url = os.getenv("OPENAI_BASE_URL", OPENAI_BASE_URL)
            self.processor = GPTProcessor(
                api_key=self.api_key, 
                base_url=base_url,
                enable_checkpoint=True  # å¯ç”¨æ–­ç‚¹åŠŸèƒ½
            )
        
        print(f"\nğŸš€ å¼€å§‹æ‰¹å¤„ç†ä»»åŠ¡")
        print(f"ğŸ“ æ–‡æœ¬æ•°é‡: {len(texts)}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
        print(f"ğŸŒ æå–æ¨¡å¼: {'åŒè¯­' if bilingual else 'å•è¯­'}")
        print("-" * 50)
        
        try:
            # æå–æ¥æºæ–‡ä»¶ä¿¡æ¯
            source_files = self._extract_source_files(texts)
            
            # è·å–ç”¨æˆ·æç¤ºè¯æ¨¡æ¿ï¼ˆä¼ å…¥bilingualå‚æ•°ï¼‰
            user_prompt_template = get_user_prompt("{text}", bilingual=bilingual)
            
            # è¿è¡Œå¤„ç†æµç¨‹ï¼Œä½†ä¸ä¿å­˜æœ€ç»ˆç»“æœ
            results = self.processor.run_extraction_only(
                texts=texts,
                system_prompt=SYSTEM_PROMPT,
                user_prompt_template=user_prompt_template,
                model=model,
                temperature=BATCH_CONFIG["temperature"],
                max_tokens=BATCH_CONFIG["max_output_tokens"],
                max_concurrent=BATCH_CONFIG["max_concurrent"],
                description="å†›äº‹èˆªå¤©æœ¯è¯­æŠ½å–ä»»åŠ¡",
                source_files=source_files
            )
            
            return results
            
        except Exception as e:
            print(f"âŒ æ‰¹å¤„ç†å¤±è´¥: {e}")
            return None
    
    # =============================================================================
    # æ–­ç‚¹ç»­ä¼ åŠŸèƒ½
    # =============================================================================
    
    def check_and_handle_checkpoints(self) -> bool:
        """
        æ£€æŸ¥å’Œå¤„ç†æ–­ç‚¹ç»­ä¼ 
        
        Returns:
            bool: å¦‚æœå¤„ç†äº†æ–­ç‚¹ç»­ä¼ åˆ™è¿”å›True
        """
        try:
            from checkpoint_manager import CheckpointManager
            checkpoint_manager = CheckpointManager()
            checkpoints = checkpoint_manager.list_checkpoints()
            
            if not checkpoints:
                return False
            
            # è¿‡æ»¤æœªå®Œæˆçš„æ–­ç‚¹
            incomplete_checkpoints = [cp for cp in checkpoints if not cp.get('is_completed', False)]
            
            if not incomplete_checkpoints:
                return False
            
            print(f"\nğŸ”„ å‘ç° {len(incomplete_checkpoints)} ä¸ªæœªå®Œæˆçš„å¤„ç†ä»»åŠ¡")
            print("ğŸ’¡ æç¤º: å¦‚æœæ–‡ä»¶å†…å®¹å·²æ›´æ”¹ï¼Œå»ºè®®é€‰æ‹©'åˆ é™¤æ‰€æœ‰å¹¶å¼€å§‹æ–°ä»»åŠ¡'")
            print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
            
            for i, cp in enumerate(incomplete_checkpoints, 1):
                progress = cp.get('progress', '0/0')
                create_time = cp.get('create_time', '')[:16]  # åªæ˜¾ç¤ºæ—¥æœŸå’Œæ—¶é—´
                print(f"  {i}. æ¢å¤ä»»åŠ¡ (åˆ›å»º: {create_time}, è¿›åº¦: {progress})")
            
            print(f"  {len(incomplete_checkpoints) + 1}. è·³è¿‡ï¼Œå¼€å§‹æ–°ä»»åŠ¡")
            print(f"  {len(incomplete_checkpoints) + 2}. åˆ é™¤æ‰€æœ‰checkpointå¹¶å¼€å§‹æ–°ä»»åŠ¡")
            
            while True:
                try:
                    choice = input(f"\nè¯·é€‰æ‹© (1-{len(incomplete_checkpoints) + 2}): ").strip()
                    choice_num = int(choice)
                    
                    if choice_num == len(incomplete_checkpoints) + 1:
                        print("â­ï¸  è·³è¿‡checkpointæ£€æŸ¥ï¼Œå¼€å§‹æ–°ä»»åŠ¡")
                        return False  # è·³è¿‡ï¼Œå¼€å§‹æ–°ä»»åŠ¡
                    
                    if choice_num == len(incomplete_checkpoints) + 2:
                        # åˆ é™¤æ‰€æœ‰checkpoint
                        print("ğŸ—‘ï¸  æ­£åœ¨åˆ é™¤æ‰€æœ‰checkpoint...")
                        import shutil
                        checkpoint_dir = Path("checkpoints")
                        if checkpoint_dir.exists():
                            for file in checkpoint_dir.glob("*.json"):
                                file.unlink()
                        print("âœ… å·²åˆ é™¤æ‰€æœ‰checkpointï¼Œå¼€å§‹æ–°ä»»åŠ¡")
                        return False
                    
                    if 1 <= choice_num <= len(incomplete_checkpoints):
                        selected_checkpoint = incomplete_checkpoints[choice_num - 1]
                        return self.resume_from_checkpoint(selected_checkpoint['checkpoint_id'])
                    
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
                    
                except (ValueError, KeyboardInterrupt):
                    print("\nâŒ è¾“å…¥æ— æ•ˆæˆ–ç”¨æˆ·å–æ¶ˆ")
                    return False
                    
        except ImportError:
            # æ–­ç‚¹åŠŸèƒ½ä¸å¯ç”¨
            return False
        except Exception as e:
            print(f"âš ï¸  æ£€æŸ¥æ–­ç‚¹æ—¶å‡ºé”™: {e}")
            return False
    
    def resume_from_checkpoint(self, checkpoint_id: str) -> bool:
        """
        ä»æ–­ç‚¹æ¢å¤å¤„ç†
        
        Args:
            checkpoint_id: æ–­ç‚¹ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ¢å¤
        """
        try:
            print(f"\nğŸ”„ æ­£åœ¨æ¢å¤æ–­ç‚¹: {checkpoint_id}")
            
            # åˆå§‹åŒ–å¤„ç†å™¨ï¼ˆå¯ç”¨æ–­ç‚¹åŠŸèƒ½ï¼‰
            base_url = os.getenv("OPENAI_BASE_URL", OPENAI_BASE_URL)
            processor = GPTProcessor(
                api_key=self.api_key, 
                base_url=base_url,
                enable_checkpoint=True
            )
            
            # åŠ è½½æ–­ç‚¹
            if not processor.load_checkpoint_for_resume(checkpoint_id):
                print("âŒ åŠ è½½æ–­ç‚¹å¤±è´¥")
                return False
            
            # è·å–æ–­ç‚¹ä¿¡æ¯
            progress = processor.get_checkpoint_progress()
            if progress:
                print(f"ğŸ“Š æ–­ç‚¹çŠ¶æ€: {progress['completed_files']}/{progress['total_files']} å·²å®Œæˆ")
                print(f"ğŸ“ˆ è¿›åº¦: {progress['progress_percentage']:.1f}%")
            
            # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„æ¢å¤é€»è¾‘
            # ç”±äºæ–­ç‚¹ç³»ç»Ÿæ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œå…ˆæ˜¾ç¤ºä¿¡æ¯
            print("âš ï¸  æ–­ç‚¹æ¢å¤åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")
            print("ğŸ’¡ æ‚¨å¯ä»¥é€‰æ‹©è·³è¿‡ï¼Œå¼€å§‹æ–°ä»»åŠ¡")
            
            return False
            
        except Exception as e:
            print(f"âŒ æ¢å¤æ–­ç‚¹å¤±è´¥: {e}")
            return False
    
    # =============================================================================
    # ä¸»ç¨‹åºæµç¨‹
    # =============================================================================
    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        print("ğŸ‰ æ¬¢è¿ä½¿ç”¨OpenAI GPTæ‰¹å¤„ç†æœ¯è¯­æŠ½å–å·¥å…·!")
        print("=" * 50)
        
        # 1. è®¾ç½®APIå¯†é’¥
        if not self.setup_api_key():
            return
        
        print("âœ… APIå¯†é’¥è®¾ç½®æˆåŠŸ")
        
        # 2. æ£€æŸ¥æ–­ç‚¹ç»­ä¼ 
        if self.check_and_handle_checkpoints():
            return
        
        # 3. é€‰æ‹©æå–æ¨¡å¼ï¼ˆå•è¯­/åŒè¯­ï¼‰- åœ¨è·å–æ–‡æœ¬ä¹‹å‰é€‰æ‹©
        bilingual = self.select_extraction_mode()
        
        # 4. è·å–è¾“å…¥æ–‡æœ¬
        texts = self.get_input_texts()
        if not texts:
            print("âŒ æ²¡æœ‰è¾“å…¥æ–‡æœ¬ï¼Œç¨‹åºé€€å‡º")
            return
        
        # 5. é€‰æ‹©æ¨¡å‹
        model = self.select_model()
        print(f"âœ… é€‰æ‹©æ¨¡å‹: {model}")
        
        # 6. è¿è¡Œæ‰¹å¤„ç†ï¼ˆåªè¿›è¡ŒæŠ½å–ï¼Œä¸ä¿å­˜æœ€ç»ˆç»“æœï¼‰
        results = self.run_batch_processing(texts, model, bilingual)
        
        if results:
            # 7. æŠ½å–å®Œæˆåï¼Œé€‰æ‹©è¾“å‡ºæ ¼å¼å¹¶æ”¯æŒé‡å¤é€‰æ‹©
            source_files = self._extract_source_files(texts)
            generated_files = self.handle_output_generation(results, source_files, model)
            
            if generated_files:
                print(f"\nğŸ‰ æ‰€æœ‰å¤„ç†å®Œæˆ!")
                print(f"ğŸ“ æ–‡ä»¶ä¿å­˜ä½ç½®: batch_results/ ç›®å½•")
                print(f"ğŸ“Š å…±ç”Ÿæˆ {len(generated_files)} ä¸ªæ–‡ä»¶")
            else:
                print("âš ï¸  æœªç”Ÿæˆä»»ä½•è¾“å‡ºæ–‡ä»¶")
            
        else:
            print("âŒ æ‰¹å¤„ç†å¤±è´¥")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="OpenAI GPTæ‰¹å¤„ç†æœ¯è¯­æŠ½å–å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python main.py                           # äº¤äº’å¼æ¨¡å¼
  python main.py --api-key YOUR_KEY       # æŒ‡å®šAPIå¯†é’¥
  python main.py --file sample.txt        # æŒ‡å®šè¾“å…¥æ–‡ä»¶
  python main.py --format csv             # æŒ‡å®šè¾“å‡ºæ ¼å¼
        """
    )
    
    parser.add_argument("--api-key", help="OpenAI APIå¯†é’¥")
    parser.add_argument("--file", help="è¾“å…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--format", choices=["json", "csv", "txt"], 
                       default="json", help="è¾“å‡ºæ ¼å¼")
    parser.add_argument("--model", help="ä½¿ç”¨çš„æ¨¡å‹")
    parser.add_argument("--chunk-size", type=int, help="æ–‡æœ¬åˆ†å—å¤§å°")
    
    args = parser.parse_args()
    
    # åˆ›å»ºåº”ç”¨å®ä¾‹
    app = TermExtractionApp()
    
    # è®¾ç½®APIå¯†é’¥
    if args.api_key:
        app.api_key = args.api_key
    
    # éäº¤äº’æ¨¡å¼
    if args.file:
        _run_non_interactive_mode(app, args)
    else:
        # äº¤äº’æ¨¡å¼
        app.run()


def _run_non_interactive_mode(app: TermExtractionApp, args):
    """è¿è¡Œéäº¤äº’æ¨¡å¼"""
    print("ğŸ¤– éäº¤äº’æ¨¡å¼è¿è¡Œ")
    
    # è®¾ç½®APIå¯†é’¥
    if not app.setup_api_key():
        return
    
    # åŠ è½½æ–‡æœ¬
    try:
        # ä½¿ç”¨é»˜è®¤é…ç½®ï¼šæ™ºèƒ½åˆ†å‰²ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šchunk_sizeåˆ™æŒ‰æ®µè½å¤„ç†
        chunk_size = args.chunk_size or TEXT_SPLITTING["default_chunk_size"]
        texts = load_texts_from_file(
            args.file, 
            chunk_size=chunk_size if args.chunk_size else None,
            use_smart_splitter=True,
            overlap_size=TEXT_SPLITTING["default_overlap_size"]
        )
        print(f"âœ… ä»æ–‡ä»¶åŠ è½½äº† {len(texts)} ä¸ªæ–‡æœ¬")
    except Exception as e:
        print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # é€‰æ‹©æ¨¡å‹
    from config import DEFAULT_MODEL
    model = args.model or DEFAULT_MODEL
    
    # è¿è¡Œæ‰¹å¤„ç†
    results = app.run_batch_processing(texts, args.format, model)
    
    if results:
        print("âœ… æ‰¹å¤„ç†å®Œæˆ!")
        for key, value in results.items():
            if value:
                print(f"  {key}: {value}")
    else:
        print("âŒ æ‰¹å¤„ç†å¤±è´¥")


if __name__ == "__main__":
    main()